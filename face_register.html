<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Face Detection</title>
		<style>
			/* General reset */
			* {
				margin: 0;
				padding: 0;
				box-sizing: border-box;
			}

			body {
				font-family: Arial, sans-serif;
				background-color: #f4f4f9;
				display: flex;
				justify-content: center;
				align-items: center;
				height: 100vh;
				flex-direction: column;
				color: #333;
			}

			/* Centering and spacing */
			h1 {
				font-size: 2rem;
				margin-bottom: 20px;
			}

			/* Link styles */
			a {
				font-size: 1rem;
				text-decoration: none;
				color: #007bff;
				margin-bottom: 20px;
			}

			a:hover {
				text-decoration: underline;
			}

			/* Video & overlay container */
			.video-wrapper {
				position: relative;
				width: 640px;
				max-width: 100%;
			}

			/* Video element */
			#video {
				border-radius: 8px;
				box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
				width: 100%;
				height: auto;
				display: block;
				transform: scaleX(-1);
			}

			/* Canvas overlays (bounding boxes, landmarks, etc.) */
			.overlay {
				position: absolute;
				top: 0;
				left: 0;
				width: 100%;
				height: 100%;
				pointer-events: none; /* allow clicks to pass through */
				display: none; /* toggled by JS */
				border-radius: 8px;
			}

			/* Snapshot canvas shown next to video */
			.snapshot {
				border: 2px solid #333;
				background-color: rgba(255, 255, 255, 0.7);
				box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
				display: none; /* toggled by JS */
				width: 640px;
				height: 480px;
				border-radius: 8px;
			}

			/* Responsive video */
			@media (max-width: 768px) {
				.video-wrapper {
					width: 100%;
				}

				.snapshot {
					max-width: 480px;
				}
			}

			/* Full-screen responsive container */
			.face-detection-container{
				width:100vw;
				height:100vh;
				display:flex;
				justify-content:center;
				align-items:center;
				flex-wrap:wrap;
				gap:1rem;
				padding:1rem;
				box-sizing:border-box;
			}

			/* Ensure the video wrapper scales while keeping the 4/3 aspect ratio */
			.video-wrapper{
				aspect-ratio:4/3;
				width:min(100vw,calc(100vh * 4 / 3));
				max-width:100%;
			}

			/* Video element keeps its intrinsic ratio */
			#video{
				width:100%;
				height:auto;
				object-fit:contain;
			}

			/* Snapshot canvas follows video size */
			.snapshot{
				width:100%;
				height:auto;
				max-height:100vh;
				aspect-ratio:4/3;
			}

			/* Adapt video & snapshot to portrait (mobile) 9:16 ratio */
			@media (orientation: portrait){
				.face-detection-container{
					flex-direction:column;
					padding:0;
				}

				.video-wrapper,
				.snapshot{
					width:100vw;
					height:100vh;
					max-width:100vw;
					max-height:100vh;
					aspect-ratio:auto;
				}

#video{
	width:100%;
	height:100%;
	object-fit:cover;
	transform: scaleX(-1);
}

.overlay{
	width:100%;
	height:100%;
	object-fit:cover;
}
			}
		</style>
		
		<!-- Load face-api core library first -->
		<script src="./js/face-api.min.js"></script>
		<!-- Then load the warm-up helper that depends on face-api -->
		<script src="./js/faceapi_warmup.js"></script>
		<script>
			function urlReplace(url) {
				window.location.replace(url); 
			}
		</script>
	</head>
	<body>
		<h1>Face Detection</h1>
		<a href="#" onclick="urlReplace('index.html')">Go to Index</a><br>
		
		<div class="face-detection-container"  style="display:flex;gap:1rem;flex-wrap:wrap;justify-content:center;">
			<div class="video-wrapper">
				<video id="video" width="640" height="480" autoplay playsinline muted></video>
				<!-- Hidden canvas for inference: captures each video frame to send to the worker for face detection -->
				<canvas id="canvas" class="overlay"></canvas>
				<!-- Overlay canvas for drawing facial landmarks on top of the video -->
				<canvas id="canvas2" class="overlay"></canvas>
				<!-- Overlay canvas for drawing face bounding boxes and confidence scores -->
				<canvas id="canvas3" class="overlay"></canvas>
			</div>
			<!-- Snapshot canvas: displays the captured face image along with the confidence percentage -->
			<canvas id="canvas_output" class="snapshot"></canvas>
		</div>

		<!-- Console Output Div -->
		<div id="console-output" style="height:150px; overflow-y:auto; background:#000; color:#fff; font-family:monospace; padding:10px; box-sizing:border-box;"></div>
		<script>
		(function() {
			var consoleDiv = document.getElementById('console-output');
			function formatArgs(args) {
				return args.map(function(arg) {
					if (typeof arg === 'object') {
						try { return JSON.stringify(arg); } catch (e) { return String(arg); }
					}
					return String(arg);
				}).join(' ');
			}
			['log','error','warn','info'].forEach(function(method) {
				var original = console[method];
				console[method] = function() {
					original.apply(console, arguments);
					var msg = formatArgs(Array.prototype.slice.call(arguments));
					var entry = document.createElement('div');
					entry.textContent = msg;
					entry.className = method;
					consoleDiv.appendChild(entry);
					consoleDiv.scrollTop = consoleDiv.scrollHeight;
				};
			});
		})();
		</script>

		<!-- Network request logging -->
		<script>
		(function(){
			// Intercept XMLHttpRequest
			var origOpen = XMLHttpRequest.prototype.open;
			XMLHttpRequest.prototype.open = function(method, url) {
				this._method = method;
				this._url = url;
				return origOpen.apply(this, arguments);
			};
			var origSend = XMLHttpRequest.prototype.send;
			XMLHttpRequest.prototype.send = function(body) {
				this.addEventListener('load', function() {
					console.log('XHR', this._method, this._url, '->', this.status);
				});
				this.addEventListener('error', function() {
					console.error('XHR ERROR', this._method, this._url);
				});
				return origSend.apply(this, arguments);
			};
			// Intercept fetch
			var origFetch = window.fetch;
			window.fetch = function(input, init) {
				var method = (init && init.method) || 'GET';
				var url = typeof input === 'string' ? input : input.url;
				console.log('Fetch', method, url);
				return origFetch.apply(this, arguments)
					.then(function(response) {
						console.log('Fetch DONE', response.status, response.url);
						return response;
					})
					.catch(function(error) {
						console.error('Fetch ERROR', url, error);
						throw error;
					});
			};
			// Log CSS load events
			document.querySelectorAll('link[rel="stylesheet"]').forEach(function(link) {
				link.addEventListener('load', function() { console.log('CSS loaded:', link.href); });
				link.addEventListener('error', function() { console.error('CSS failed to load:', link.href); });
			});
		})();
		</script>

		<!-- Resource timing logging -->
		<script>
		(function(){
			if ('PerformanceObserver' in window) {
				var observer = new PerformanceObserver(function(list) {
					list.getEntries().forEach(function(entry) {
						console.log('Resource', entry.initiatorType, entry.name, Math.round(entry.duration) + 'ms');
					});
				});
				observer.observe({ entryTypes: ['resource'], buffered: true });
			} else {
				console.warn('PerformanceObserver not supported for resource logging');
			}
		})();
		</script>

		<script>
			/**
			 * ================================
			 * Face-API Configuration
			 * -------------------------------
			 * faceapi_action
			 *   • "verify"   – Compare the live video frame against a previously
			 *     registered reference descriptor (used in a face-verification flow).
			 *   • "register" – Capture the detected face descriptor and store it as
			 *     a new reference (used when enrolling a new user).
			 *
			 * face_detector_options_setup
			 *   These options are forwarded to face-api.js TinyFaceDetector and allow
			 *   you to balance performance vs. accuracy according to your use-case.
			 *   • inputSize        – Dimension (square) of the NN input. Larger numbers
			 *                         improve accuracy but require more computation.
			 *   • scoreThreshold   – Minimum confidence score (0-1) that a detection
			 *                         must reach to be considered valid. 0.8 = 80%.
			 *   • maxDetectedFaces – Hard limit on how many faces should be processed
			 *                         per frame. Keeping it at 1 speeds things up when
			 *                         you only care about the user in front of the
			 *                         camera.
			 * ================================
			 */
			var faceapi_action = "register"; // verify, register
			var warmup_completed = [camera_start, video_face_detection];
			var face_detector_options_setup = {
				inputSize: 128,
				scoreThreshold: 0.75, // 0.8 = 80%
				maxDetectedFaces: 1,
			};
		</script>
	</body>
</html>
